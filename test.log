throughput.py:107: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  config = yaml.load(result)
Some weights of the model checkpoint at /home/yangyu/Throughput_And_Latency/huggingface_pretrained_model/albert_chinese_tiny were not used when initializing AlbertModel: ['predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.bias', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2021-07-19 10:35:48,116 - INFO - 构建数据集...
2021-07-19 10:36:20,475 - INFO - 构建完成...100000条数据...
2021-07-19 10:36:20,477 - INFO - albert model!
2021-07-19 10:36:20,477 - INFO - ******************
2021-07-19 10:36:20,477 - INFO - max_length:16
2021-07-19 10:36:23,476 - INFO - （100）以内batch_size大小对应的推理时间：
2021-07-19 10:36:23,476 - INFO - {2: 0.2689087390899658, 4: 0.008884191513061523, 6: 0.009140491485595703, 8: 0.008831977844238281, 10: 0.00925588607788086, 12: 0.0088653564453125, 14: 0.008507251739501953, 16: 0.008514642715454102, 18: 0.00851583480834961, 20: 0.008552074432373047, 22: 0.00888371467590332, 24: 0.008840322494506836, 26: 0.008516311645507812, 28: 0.009181499481201172, 30: 0.008864641189575195, 32: 0.008903741836547852, 34: 0.008890390396118164, 36: 0.009880781173706055, 38: 0.008536577224731445, 40: 0.00852656364440918, 42: 0.009394645690917969, 44: 0.008687496185302734, 46: 0.008692502975463867, 48: 0.008989095687866211, 50: 0.008637666702270508, 52: 0.008654117584228516, 54: 0.009400129318237305, 56: 0.008625268936157227, 58: 0.008627176284790039, 60: 0.008610010147094727, 62: 0.009006738662719727, 64: 0.008605003356933594, 66: 0.008615255355834961, 68: 0.008613824844360352, 70: 0.008626937866210938, 72: 0.008606195449829102, 74: 0.00861358642578125, 76: 0.009007453918457031, 78: 0.008629083633422852, 80: 0.008640289306640625, 82: 0.008648395538330078, 84: 0.008632659912109375, 86: 0.008987665176391602, 88: 0.008619546890258789, 90: 0.00862741470336914, 92: 0.008635759353637695, 94: 0.008629560470581055, 96: 0.008640766143798828, 98: 0.008629083633422852}
2021-07-19 10:37:54,758 - INFO - 最大batch_size：16200
2021-07-19 10:37:54,758 - INFO - batch_size大小对应的推理时间：
2021-07-19 10:37:54,758 - INFO - {100: 0.009021282196044922, 200: 0.011422395706176758, 300: 0.01163339614868164, 400: 0.011731147766113281, 500: 0.011802434921264648, 600: 0.016470670700073242, 700: 0.018429994583129883, 800: 0.020334243774414062, 900: 0.02504730224609375, 1000: 0.025179386138916016, 1100: 0.030972719192504883, 1200: 0.029703855514526367, 1300: 0.032423973083496094, 1400: 0.03982377052307129, 1500: 0.041948795318603516, 1600: 0.04063916206359863, 1700: 0.04282712936401367, 1800: 0.051508426666259766, 1900: 0.05501055717468262, 2000: 0.014391899108886719, 2100: 0.05317091941833496, 2200: 0.06400489807128906, 2300: 0.06661272048950195, 2400: 0.061228275299072266, 2500: 0.06423139572143555, 2600: 0.07566046714782715, 2700: 0.7637982368469238, 2800: 0.01438140869140625, 2900: 0.07611584663391113, 3000: 0.08570122718811035, 3100: 0.08885002136230469, 3200: 0.0814816951751709, 3300: 0.08518862724304199, 3400: 0.09961438179016113, 3500: 0.10309958457946777, 3600: 0.09383058547973633, 3700: 0.6283609867095947, 3800: 0.05758953094482422, 3900: 0.08390045166015625, 4000: 0.10344958305358887, 4100: 0.10640382766723633, 4200: 0.12102556228637695, 4300: 0.12398266792297363, 4400: 0.5752758979797363, 4500: 0.06499433517456055, 4600: 0.10199284553527832, 4700: 0.1362748146057129, 4800: 0.12358522415161133, 4900: 0.01670527458190918, 5000: 0.6122322082519531, 5100: 0.07247543334960938, 5200: 0.09235978126525879, 5300: 0.1349928379058838, 5400: 0.1547093391418457, 5500: 0.627845287322998, 5600: 0.06859755516052246, 5700: 0.10700750350952148, 5800: 0.168290376663208, 5900: 0.6028766632080078, 6000: 0.07126355171203613, 6100: 0.11605167388916016, 6200: 0.17871665954589844, 6300: 0.6179933547973633, 6400: 0.023270606994628906, 6500: 0.16200566291809082, 6600: 0.1952507495880127, 6700: 0.658555269241333, 6800: 0.048418283462524414, 6900: 0.1575300693511963, 7000: 0.6734869480133057, 7100: 0.0523228645324707, 7200: 0.16518139839172363, 7300: 0.64365553855896, 7400: 0.06813240051269531, 7500: 0.029607057571411133, 7600: 0.6473922729492188, 7700: 0.04515409469604492, 7800: 0.19259142875671387, 7900: 0.6941726207733154, 8000: 0.030950546264648438, 8100: 0.2121601104736328, 8200: 0.785332202911377, 8300: 0.024072885513305664, 8400: 0.6311616897583008, 8500: 0.022891521453857422, 8600: 0.902759313583374, 8700: 0.02422046661376953, 8800: 0.8733096122741699, 8900: 0.029222726821899414, 9000: 0.9095845222473145, 9100: 0.029572725296020508, 9200: 0.6167469024658203, 9300: 0.02948474884033203, 9400: 0.9215443134307861, 9500: 0.03235578536987305, 9600: 0.8909866809844971, 9700: 0.023127317428588867, 9800: 0.9464778900146484, 9900: 0.027267932891845703, 10000: 0.6526460647583008, 10100: 0.02763819694519043, 10200: 0.954380989074707, 10300: 0.02871847152709961, 10400: 0.8206639289855957, 10500: 0.057395219802856445, 10600: 0.8682007789611816, 10700: 0.03103780746459961, 10800: 0.9331886768341064, 10900: 0.5827863216400146, 11000: 0.6375148296356201, 11100: 0.6335561275482178, 11200: 0.6280531883239746, 11300: 0.6674473285675049, 11400: 0.6755282878875732, 11500: 0.6542534828186035, 11600: 0.6260924339294434, 11700: 0.6737556457519531, 11800: 0.6759207248687744, 11900: 0.632277250289917, 12000: 0.595707893371582, 12100: 0.650360107421875, 12200: 0.6622345447540283, 12300: 0.6488234996795654, 12400: 0.624779224395752, 12500: 0.6309361457824707, 12600: 0.661309003829956, 12700: 0.6322600841522217, 12800: 0.6405744552612305, 12900: 0.7262909412384033, 13000: 0.6470773220062256, 13100: 0.7693448066711426, 13200: 0.6432733535766602, 13300: 0.7588002681732178, 13400: 0.7984535694122314, 13500: 0.6333799362182617, 13600: 0.7623581886291504, 13700: 0.7893118858337402, 13800: 0.8253741264343262, 13900: 0.8087737560272217, 14000: 0.6643950939178467, 14100: 0.8089625835418701, 14200: 0.9490752220153809, 14300: 0.6586909294128418, 14400: 0.7429590225219727, 14500: 0.6703169345855713, 14600: 0.9324607849121094, 14700: 0.8394956588745117, 14800: 0.6416258811950684, 14900: 0.6677379608154297, 15000: 0.9577667713165283, 15100: 0.7859385013580322, 15200: 0.9033041000366211, 15300: 0.6473073959350586, 15400: 0.916332483291626, 15500: 0.7515251636505127, 15600: 0.8819963932037354, 15700: 0.6643228530883789, 15800: 1.0208539962768555, 15900: 0.9873495101928711, 16000: 1.336601972579956, 16100: 1.2090725898742676, 16200: 1.064168930053711}
2021-07-19 10:37:54,758 - INFO - 吞吐量：15317.11699116916
2021-07-19 10:37:54,758 - INFO - ******************
Some weights of the model checkpoint at /home/yangyu/Throughput_And_Latency/huggingface_pretrained_model/albert_chinese_tiny were not used when initializing AlbertModel: ['predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.bias', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2021-07-19 10:37:55,083 - INFO - 构建数据集...
2021-07-19 10:38:27,986 - INFO - 构建完成...100000条数据...
2021-07-19 10:38:27,987 - INFO - albert model!
2021-07-19 10:38:27,987 - INFO - ******************
2021-07-19 10:38:27,987 - INFO - max_length:32
2021-07-19 10:38:28,418 - INFO - （100）以内batch_size大小对应的推理时间：
2021-07-19 10:38:28,418 - INFO - {2: 0.008470535278320312, 4: 0.007611513137817383, 6: 0.008597373962402344, 8: 0.007549285888671875, 10: 0.007570028305053711, 12: 0.009417533874511719, 14: 0.008429288864135742, 16: 0.007755756378173828, 18: 0.01177215576171875, 20: 0.007070302963256836, 22: 0.007258415222167969, 24: 0.007227897644042969, 26: 0.0071947574615478516, 28: 0.007166624069213867, 30: 0.0071604251861572266, 32: 0.007150888442993164, 34: 0.007155895233154297, 36: 0.0071642398834228516, 38: 0.00718998908996582, 40: 0.0071752071380615234, 42: 0.007147073745727539, 44: 0.00716090202331543, 46: 0.007160186767578125, 48: 0.007160186767578125, 50: 0.007155418395996094, 52: 0.0071756839752197266, 54: 0.007154226303100586, 56: 0.0071659088134765625, 58: 0.0071659088134765625, 60: 0.007165431976318359, 62: 0.007155179977416992, 64: 0.007149457931518555, 66: 0.007147073745727539, 68: 0.00720524787902832, 70: 0.00717616081237793, 72: 0.0071604251861572266, 74: 0.007169246673583984, 76: 0.007349967956542969, 78: 0.0073544979095458984, 80: 0.007308244705200195, 82: 0.0072841644287109375, 84: 0.00856161117553711, 86: 0.008700370788574219, 88: 0.008791446685791016, 90: 0.008855342864990234, 92: 0.008996963500976562, 94: 0.009064435958862305, 96: 0.009192943572998047, 98: 0.009211540222167969}
2021-07-19 10:38:46,323 - INFO - 最大batch_size：6200
2021-07-19 10:38:46,323 - INFO - batch_size大小对应的推理时间：
2021-07-19 10:38:46,323 - INFO - {100: 0.009270906448364258, 200: 0.008335351943969727, 300: 0.014960289001464844, 400: 0.02403855323791504, 500: 0.02934432029724121, 600: 0.04044342041015625, 700: 0.04417729377746582, 800: 0.05549192428588867, 900: 0.05793261528015137, 1000: 0.0721437931060791, 1100: 0.07324671745300293, 1200: 0.09013605117797852, 1300: 0.08491110801696777, 1400: 0.10413146018981934, 1500: 0.10248231887817383, 1600: 0.11925911903381348, 1700: 0.11641764640808105, 1800: 0.13592147827148438, 1900: 0.13143134117126465, 2000: 0.1512908935546875, 2100: 0.1456594467163086, 2200: 0.16679859161376953, 2300: 0.16042017936706543, 2400: 0.182570219039917, 2500: 0.17442536354064941, 2600: 0.19844269752502441, 2700: 0.189378023147583, 2800: 0.21445631980895996, 2900: 0.2010047435760498, 3000: 0.22760367393493652, 3100: 0.21700000762939453, 3200: 0.24526429176330566, 3300: 0.23134160041809082, 3400: 0.261141300201416, 3500: 0.008245229721069336, 3600: 0.2758042812347412, 3700: 0.25914812088012695, 3800: 0.2917134761810303, 3900: 0.273665189743042, 4000: 0.29654693603515625, 4100: 0.28571653366088867, 4200: 0.32207536697387695, 4300: 0.30166149139404297, 4400: 0.33788180351257324, 4500: 0.3153226375579834, 4600: 0.35352444648742676, 4700: 0.3323020935058594, 4800: 0.35537028312683105, 4900: 0.34139156341552734, 5000: 0.3839137554168701, 5100: 0.35813450813293457, 5200: 0.398853063583374, 5300: 0.37153172492980957, 5400: 0.41560840606689453, 5500: 0.1413125991821289, 5600: 0.4138154983520508, 5700: 0.385725736618042, 5800: 0.43070554733276367, 5900: 0.9356601238250732, 6000: 0.012322664260864258, 6100: 0.40860867500305176, 6200: 0.45830821990966797}
2021-07-19 10:38:46,323 - INFO - 吞吐量：13746.207740375512
2021-07-19 10:38:46,323 - INFO - ******************
Some weights of the model checkpoint at /home/yangyu/Throughput_And_Latency/huggingface_pretrained_model/albert_chinese_tiny were not used when initializing AlbertModel: ['predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.bias', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2021-07-19 10:38:46,668 - INFO - 构建数据集...
2021-07-19 10:39:20,560 - INFO - 构建完成...100000条数据...
2021-07-19 10:39:20,561 - INFO - albert model!
2021-07-19 10:39:20,561 - INFO - ******************
2021-07-19 10:39:20,561 - INFO - max_length:64
2021-07-19 10:39:21,157 - INFO - （100）以内batch_size大小对应的推理时间：
2021-07-19 10:39:21,157 - INFO - {2: 0.008306264877319336, 4: 0.007567405700683594, 6: 0.00819540023803711, 8: 0.008745670318603516, 10: 0.009959697723388672, 12: 0.007348060607910156, 14: 0.007105350494384766, 16: 0.007103443145751953, 18: 0.00708317756652832, 20: 0.0070953369140625, 22: 0.007092952728271484, 24: 0.007096052169799805, 26: 0.007122516632080078, 28: 0.007080793380737305, 30: 0.007096290588378906, 32: 0.007082939147949219, 34: 0.007635831832885742, 36: 0.00790858268737793, 38: 0.008099794387817383, 40: 0.008385419845581055, 42: 0.008448123931884766, 44: 0.010167121887207031, 46: 0.01024174690246582, 48: 0.010585308074951172, 50: 0.010360479354858398, 52: 0.010491371154785156, 54: 0.010716438293457031, 56: 0.01129150390625, 58: 0.011327505111694336, 60: 0.01196742057800293, 62: 0.012215137481689453, 64: 0.013056516647338867, 66: 0.012836694717407227, 68: 0.013469696044921875, 70: 0.013343572616577148, 72: 0.013982772827148438, 74: 0.013756752014160156, 76: 0.014083385467529297, 78: 0.01387476921081543, 80: 0.014646291732788086, 82: 0.014388799667358398, 84: 0.016185522079467773, 86: 0.01602649688720703, 88: 0.016759634017944336, 90: 0.01632976531982422, 92: 0.017368078231811523, 94: 0.016889333724975586, 96: 0.01827216148376465, 98: 0.01746988296508789}
2021-07-19 10:39:28,380 - INFO - 最大batch_size：2700
2021-07-19 10:39:28,380 - INFO - batch_size大小对应的推理时间：
2021-07-19 10:39:28,380 - INFO - {100: 0.018828630447387695, 200: 0.016750335693359375, 300: 0.03309988975524902, 400: 0.04988908767700195, 500: 0.06609249114990234, 600: 0.08286452293395996, 700: 0.09918928146362305, 800: 0.1153724193572998, 900: 0.1322484016418457, 1000: 0.14899539947509766, 1100: 0.1651630401611328, 1200: 0.1819915771484375, 1300: 0.19839906692504883, 1400: 0.21509623527526855, 1500: 0.23139333724975586, 1600: 0.24778342247009277, 1700: 0.2637205123901367, 1800: 0.2800619602203369, 1900: 0.2977626323699951, 2000: 0.3135511875152588, 2100: 0.32988929748535156, 2200: 0.34615349769592285, 2300: 0.3626060485839844, 2400: 0.37813901901245117, 2500: 0.3958563804626465, 2600: 0.40999865531921387, 2700: 0.4261014461517334}
2021-07-19 10:39:28,380 - INFO - 吞吐量：6571.205109223987
2021-07-19 10:39:28,380 - INFO - ******************
Some weights of the model checkpoint at /home/yangyu/Throughput_And_Latency/huggingface_pretrained_model/bert-base-chinese were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2021-07-19 10:39:30,425 - INFO - 构建数据集...
2021-07-19 10:40:02,874 - INFO - 构建完成...100000条数据...
2021-07-19 10:40:02,875 - INFO - bert model!
2021-07-19 10:40:02,875 - INFO - ******************
2021-07-19 10:40:02,875 - INFO - max_length:16
2021-07-19 10:40:04,495 - INFO - （100）以内batch_size大小对应的推理时间：
2021-07-19 10:40:04,495 - INFO - {2: 0.020634174346923828, 4: 0.023093461990356445, 6: 0.018739938735961914, 8: 0.02044963836669922, 10: 0.05031919479370117, 12: 0.022905826568603516, 14: 0.019605636596679688, 16: 0.024470090866088867, 18: 0.019832372665405273, 20: 0.022369861602783203, 22: 0.019703388214111328, 24: 0.01969432830810547, 26: 0.019542932510375977, 28: 0.0195314884185791, 30: 0.019461393356323242, 32: 0.019471406936645508, 34: 0.019524097442626953, 36: 0.020114421844482422, 38: 0.020473003387451172, 40: 0.019574642181396484, 42: 0.019817590713500977, 44: 0.023205995559692383, 46: 0.02370476722717285, 48: 0.024125099182128906, 50: 0.02446913719177246, 52: 0.025548934936523438, 54: 0.025631189346313477, 56: 0.026883840560913086, 58: 0.0273892879486084, 60: 0.029167652130126953, 62: 0.029372215270996094, 64: 0.030436277389526367, 66: 0.030759334564208984, 68: 0.032767295837402344, 70: 0.03322410583496094, 72: 0.03424501419067383, 74: 0.03381490707397461, 76: 0.03186774253845215, 78: 0.03248190879821777, 80: 0.032656192779541016, 82: 0.033217430114746094, 84: 0.04368305206298828, 86: 0.0440211296081543, 88: 0.044397830963134766, 90: 0.04488778114318848, 92: 0.046327829360961914, 94: 0.04655051231384277, 96: 0.04681110382080078, 98: 0.04722857475280762}
2021-07-19 10:40:16,065 - INFO - 最大batch_size：2200
2021-07-19 10:40:16,065 - INFO - batch_size大小对应的推理时间：
2021-07-19 10:40:16,065 - INFO - {100: 0.04820704460144043, 200: 0.04769730567932129, 300: 0.08735299110412598, 400: 0.12380433082580566, 500: 0.16027593612670898, 600: 0.2079169750213623, 700: 0.24695706367492676, 800: 0.2818937301635742, 900: 0.31998229026794434, 1000: 0.36986780166625977, 1100: 0.40615057945251465, 1200: 0.44362878799438477, 1300: 0.4841480255126953, 1400: 0.5292177200317383, 1500: 0.5676684379577637, 1600: 0.6088786125183105, 1700: 0.6490805149078369, 1800: 0.6916584968566895, 1900: 0.7361199855804443, 2000: 0.7728393077850342, 2100: 0.8186688423156738, 2200: 0.8564863204956055}
2021-07-19 10:40:16,065 - INFO - 吞吐量：2685.3902332837097
2021-07-19 10:40:16,065 - INFO - ******************
Some weights of the model checkpoint at /home/yangyu/Throughput_And_Latency/huggingface_pretrained_model/bert-base-chinese were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2021-07-19 10:40:18,014 - INFO - 构建数据集...
2021-07-19 10:40:50,842 - INFO - 构建完成...100000条数据...
2021-07-19 10:40:50,844 - INFO - bert model!
2021-07-19 10:40:50,844 - INFO - ******************
2021-07-19 10:40:50,844 - INFO - max_length:32
2021-07-19 10:40:53,343 - INFO - （100）以内batch_size大小对应的推理时间：
2021-07-19 10:40:53,344 - INFO - {2: 0.02743816375732422, 4: 0.02086186408996582, 6: 0.02749490737915039, 8: 0.026363849639892578, 10: 0.023107528686523438, 12: 0.019751787185668945, 14: 0.019537925720214844, 16: 0.01952528953552246, 18: 0.02051377296447754, 20: 0.020745038986206055, 22: 0.020581722259521484, 24: 0.02489495277404785, 26: 0.025856971740722656, 28: 0.027206897735595703, 30: 0.028873682022094727, 32: 0.03090381622314453, 34: 0.031813621520996094, 36: 0.03448629379272461, 38: 0.03475522994995117, 40: 0.03354763984680176, 42: 0.034017086029052734, 44: 0.04441118240356445, 46: 0.045992136001586914, 48: 0.0482172966003418, 50: 0.04904818534851074, 52: 0.050377845764160156, 54: 0.051598548889160156, 56: 0.053156137466430664, 58: 0.05406641960144043, 60: 0.05714821815490723, 62: 0.0574948787689209, 64: 0.059844017028808594, 66: 0.06038093566894531, 68: 0.06162214279174805, 70: 0.06228184700012207, 72: 0.0635824203491211, 74: 0.06428265571594238, 76: 0.06559634208679199, 78: 0.06594038009643555, 80: 0.06709861755371094, 82: 0.06778836250305176, 84: 0.07837915420532227, 86: 0.0791025161743164, 88: 0.08063101768493652, 90: 0.08117938041687012, 92: 0.08419418334960938, 94: 0.08534407615661621, 96: 0.08586311340332031, 98: 0.08644270896911621}
2021-07-19 10:40:59,909 - INFO - 最大batch_size：1100
2021-07-19 10:40:59,909 - INFO - batch_size大小对应的推理时间：
2021-07-19 10:40:59,909 - INFO - {100: 0.089813232421875, 200: 0.08990788459777832, 300: 0.1643962860107422, 400: 0.2534468173980713, 500: 0.3284313678741455, 600: 0.41608643531799316, 700: 0.49620628356933594, 800: 0.579193115234375, 900: 0.6611480712890625, 1000: 0.7465686798095703, 1100: 0.8333947658538818}
2021-07-19 10:40:59,909 - INFO - 吞吐量：1439.8938524295875
2021-07-19 10:40:59,909 - INFO - ******************
Some weights of the model checkpoint at /home/yangyu/Throughput_And_Latency/huggingface_pretrained_model/bert-base-chinese were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2021-07-19 10:41:02,165 - INFO - 构建数据集...
2021-07-19 10:41:35,812 - INFO - 构建完成...100000条数据...
2021-07-19 10:41:35,814 - INFO - bert model!
2021-07-19 10:41:35,814 - INFO - ******************
2021-07-19 10:41:35,814 - INFO - max_length:64
2021-07-19 10:41:40,342 - INFO - （100）以内batch_size大小对应的推理时间：
2021-07-19 10:41:40,342 - INFO - {2: 0.030559778213500977, 4: 0.036859750747680664, 6: 0.019622325897216797, 8: 0.019357919692993164, 10: 0.02072906494140625, 12: 0.022258520126342773, 14: 0.02742457389831543, 16: 0.031351566314697266, 18: 0.03505420684814453, 20: 0.036745309829711914, 22: 0.036798954010009766, 24: 0.049585580825805664, 26: 0.05084943771362305, 28: 0.052492380142211914, 30: 0.05537676811218262, 32: 0.05885815620422363, 34: 0.06212615966796875, 36: 0.06385636329650879, 38: 0.06515336036682129, 40: 0.06746602058410645, 42: 0.0696415901184082, 44: 0.08067989349365234, 46: 0.0828404426574707, 48: 0.08718109130859375, 50: 0.08847856521606445, 52: 0.09297752380371094, 54: 0.09519815444946289, 56: 0.09691119194030762, 58: 0.09894275665283203, 60: 0.10155367851257324, 62: 0.10271596908569336, 64: 0.11691617965698242, 66: 0.11489224433898926, 68: 0.12055754661560059, 70: 0.12216973304748535, 72: 0.12704062461853027, 74: 0.12717247009277344, 76: 0.13103461265563965, 78: 0.13200831413269043, 80: 0.1353611946105957, 82: 0.1370525360107422, 84: 0.1476612091064453, 86: 0.14959073066711426, 88: 0.15418124198913574, 90: 0.1559913158416748, 92: 0.1601860523223877, 94: 0.16137456893920898, 96: 0.16440749168395996, 98: 0.16512465476989746}
2021-07-19 10:41:43,064 - INFO - 最大batch_size：400
2021-07-19 10:41:43,065 - INFO - batch_size大小对应的推理时间：
2021-07-19 10:41:43,065 - INFO - {100: 0.16859674453735352, 200: 0.16823840141296387, 300: 0.33580541610717773, 400: 0.5069406032562256}
2021-07-19 10:41:43,065 - INFO - 吞吐量：986.3088432616285
2021-07-19 10:41:43,065 - INFO - ******************
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
3200
3300
3400
3500
3600
3700
3800
3900
4000
4100
4200
4300
4400
4500
4600
4700
4800
4900
5000
5100
5200
5300
5400
5500
5600
5700
5800
5900
6000
6100
6200
6300
6400
6500
6600
6700
6800
6900
7000
7100
7200
7300
7400
7500
7600
7700
7800
7900
8000
8100
8200
8300
8400
8500
8600
8700
8800
8900
9000
9100
9200
9300
9400
9500
9600
9700
9800
9900
10000
10100
10200
10300
10400
10500
10600
10700
10800
10900
11000
11100
11200
11300
11400
11500
11600
11700
11800
11900
12000
12100
12200
12300
12400
12500
12600
12700
12800
12900
13000
13100
13200
13300
13400
13500
13600
13700
13800
13900
14000
14100
14200
14300
14400
14500
14600
14700
14800
14900
15000
15100
15200
15300
15400
15500
15600
15700
15800
15900
16000
16100
16200
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
3200
3300
3400
3500
3600
3700
3800
3900
4000
4100
4200
4300
4400
4500
4600
4700
4800
4900
5000
5100
5200
5300
5400
5500
5600
5700
5800
5900
6000
6100
6200
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
100
200
300
400
500
600
700
800
900
1000
1100
100
200
300
400
